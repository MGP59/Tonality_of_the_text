{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практические задание №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача -- определить тональность текста по шкале от 1 (негативный) до 10 (позитивный).\n",
    "Ввод: тексты, разделенные переводом строки (\\n).\n",
    "Вывод: для каждого текста из входных данных вывести тональную оценку от 1 до 10. Разделитель между выводами для разных текстов -- перевод строки (\\n).\n",
    "\n",
    "Для обучения можно использовать коллекцию текстов и соответствующие им оценки. Файл обучающей коллекции соответствует формату ввода, файл с оценками -- формату вывода; кодировка -- UTF-8.\n",
    "\n",
    "В качестве оценки используется квадратный корень из среднеквадратической ошибки (Root Mean Squared Error) .\n",
    "\n",
    "Вы можете кратко описать решение в первой строке загружаемого файла после символа #. Информация будет полезна авторам курса, чтобы составить представление об используемых методах и подходах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка необходимых библиотек \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from natasha import MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, NewsNERTagger, Doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сериал очень люблю, но Академия и Земля вызыва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>думал, что будет лучше идея очень интересна - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>с творчеством Головачева я познакомился посред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>то-то я и в большое неудовольствие прочитал \"А...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как мне показалось местами сильно смахивает на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Сериал очень люблю, но Академия и Земля вызыва...\n",
       "1  думал, что будет лучше идея очень интересна - ...\n",
       "2  с творчеством Головачева я познакомился посред...\n",
       "3  то-то я и в большое неудовольствие прочитал \"А...\n",
       "4  как мне показалось местами сильно смахивает на..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные из файла `texts_train.txt`, посмотрим на них\n",
    "import csv \n",
    "\n",
    "texts_train = pd.read_csv(\n",
    "    'C:/Users/Григорий/Notebooks (Pyton)/Обработка_языка/Практическое_задание_3/texts_train.txt', \n",
    "    sep='\\n', header=None, encoding='utf-8', error_bad_lines=False, quoting=csv.QUOTE_NONE) \n",
    "    '''Так как поля содержат кавычки, чтобы не возникало ошибок, \n",
    "       не будем обрабатывать: quoting=csv.QUOTE_NONE'''\n",
    "texts_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       20000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_train.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   6\n",
       "1   7\n",
       "2  10\n",
       "3   5\n",
       "4   6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные из файла `scores_train.txt`, посмотрим на них\n",
    "\n",
    "scores_train = pd.read_csv(\n",
    "    'C:/Users/Григорий/Notebooks (Pyton)/Обработка_языка/Практическое_задание_3/scores_train.txt', \n",
    "    sep=\"\\n\", header=None, error_bad_lines=False) \n",
    "scores_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       20000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 156.4 KB\n"
     ]
    }
   ],
   "source": [
    "scores_train.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, количество строк одинаковое, теперь можем записать наши данные в параметры и целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = texts_train[0] \n",
    "y = scores_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учтем, что у нас входные данные на русском языке и слова имеют разные окончания. Приведем их к одному виду с помощью лемматизации, а также используем результаты синтаксического разбора, учтем связи между словами, нормализуем именованные сущности. В этом нам поможет `Natasha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding() \n",
    "morph_vocab = MorphVocab() \n",
    "segmenter = Segmenter() \n",
    "morph_tagger = NewsMorphTagger(emb) \n",
    "syntax_parser = NewsSyntaxParser(emb) \n",
    "ner_tagger = NewsNERTagger(emb) \n",
    "\n",
    "# Функция для получения списка токенов для русского языка\n",
    "\n",
    "def docVocab(text): \n",
    "    doc = Doc(text) \n",
    "    doc.segment(segmenter) \n",
    "    doc.tag_morph(morph_tagger) \n",
    "    \n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab) \n",
    "        \n",
    "    lemms = {_.text: _.lemma for _ in doc.tokens if _.pos != 'PUNCT'} \n",
    "    \n",
    "    doc.parse_syntax(syntax_parser) \n",
    "    doc.tag_ner(ner_tagger) \n",
    "    \n",
    "    for span in doc.spans:\n",
    "        span.normalize(morph_vocab)\n",
    "    \n",
    "    spans = {_.text: _.normal for _ in doc.spans} \n",
    "    lemms.update(spans) \n",
    "    \n",
    "    return list(lemms.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим функцию, написанную выше для предобработки входных данных, перед этим приведем в строки\n",
    "\n",
    "X = X.apply(str) \n",
    "X_new = X.apply(lambda x: ' '.join(docVocab(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем выборку предобработанных данных на обучающую и тестовую\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y[0], test_size=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_new = Pipeline([('vector', CountVectorizer()), \n",
    "                       ('tfidf', TfidfTransformer()), \n",
    "                       ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf_new = text_clf_new.fit(X_train_new, y_train_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_new = text_clf_new.predict(X_test_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.88\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Squared Error \n",
    "\n",
    "RMSE = (mean_squared_error(y_test_new, y_predicted_new))**0.5 \n",
    "print(f'{RMSE:.2f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем параметры для получения более лучшего RMSE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "parameters = {'vector__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "              'tfidf__use_idf': (True, False), \n",
    "              'clf__alpha': (1e-2, 1e-3)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vector', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]) \n",
    "grid_search_clf = GridSearchCV(text_clf, parameters, scoring=mean_squared_error, n_jobs=-1)\n",
    "grid_search_clf = grid_search_clf.fit(X_train_new, y_train_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30593333333333333,\n",
       " {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vector__ngram_range': (1, 2)})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на параметры\n",
    "\n",
    "grid_search_clf.best_score_, grid_search_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для использования cross_val_score\n",
    "\n",
    "def estimate_mse(clf, X, y, cv=5, scoring=mean_squared_error):\n",
    "    return cross_val_score(clf, X, y, cv=5, scoring=mean_squared_error).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_param = grid_search_clf.best_params_ \n",
    "\n",
    "text_clf = Pipeline([('vector', CountVectorizer(ngram_range=grid_search_param['vector__ngram_range'])), \n",
    "                     ('tfidf', TfidfTransformer(use_idf=grid_search_param['tfidf__use_idf'])), \n",
    "                     ('clf', MultinomialNB(alpha=grid_search_param['clf__alpha']))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer(use_idf=False)), ('clf', SVC())])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "text_clf_svm = Pipeline([('vector', CountVectorizer(ngram_range=(1, 2))), \n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)), \n",
    "                         ('clf', svm.SVC())]) \n",
    "text_clf_svm.fit(X_train_new, y_train_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = text_clf_svm.predict(X_test_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.40\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Squared Error \n",
    "\n",
    "RMSE_svm = (mean_squared_error(y_test_new, y_pred_new))**0.5 \n",
    "print(f'{RMSE_svm:.2f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM показывает более хороший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer(use_idf=False)), ('clf', SVC())])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модель на всех данных: \n",
    "\n",
    "X = texts_train[0] \n",
    "y = scores_train[0] \n",
    "text_svm = Pipeline([('vector', CountVectorizer(ngram_range=(1, 2))), \n",
    "                    ('tfidf', TfidfTransformer(use_idf=False)), \n",
    "                    ('clf', svm.SVC())]) \n",
    "text_svm.fit(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь предскажем оценки на входных данных: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нет, с \"Американской трагедией\" ни в какое сра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Очень добрый, красивый и, несмотря на внешнюю ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Лёгонькая книжечка на тему истории семьи Бордж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Фильм хороший. Музыка, танцы. Особенно на выпу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Стоящее кино. Мне оно показалось чем-то между ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Нет, с \"Американской трагедией\" ни в какое сра...\n",
       "1  Очень добрый, красивый и, несмотря на внешнюю ...\n",
       "2  Лёгонькая книжечка на тему истории семьи Бордж...\n",
       "3  Фильм хороший. Музыка, танцы. Особенно на выпу...\n",
       "4  Стоящее кино. Мне оно показалось чем-то между ..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные из файла `dataset_40757_1.txt`, посмотрим на них\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    'C:/Users/Григорий/Notebooks (Pyton)/Обработка_языка/Практическое_задание_3/dataset_40757_1.txt', \n",
    "    sep='\\n', header=None, encoding='utf-8', error_bad_lines=False, quoting=csv.QUOTE_NONE) \n",
    "'''Так как поля содержат кавычки, чтобы не возникало ошибок, \n",
    "                   не будем обрабатывать: quoting=csv.QUOTE_NONE'''\n",
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим функцию, написанную выше для предобработки входных данных, перед этим приведем в строки\n",
    "\n",
    "X_dataset = dataset[0].apply(str) \n",
    "X_dataset = X_dataset.apply(lambda x: ' '.join(docVocab(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предскажем значения \n",
    "\n",
    "y_pred = text_svm.predict(X_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним файл `predictions.txt` \n",
    "\n",
    "pd.DataFrame(y_pred).to_csv('predictions.txt', sep='\\n', header=None, index=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  9,  8,  8, 10,  8,  9, 10,  8,  9,  9,  9,  9, 10,  9,  8, 10,\n",
       "       10,  8, 10, 10,  9, 10,  8, 10,  9,  8,  9,  8, 10,  9,  9,  9,  8,\n",
       "       10, 10, 10, 10, 10,  9,  9, 10,  9,  9, 10, 10,  8, 10,  9, 10, 10,\n",
       "        9, 10, 10,  8, 10,  9,  8, 10,  9, 10, 10,  9,  9,  9,  8,  8, 10,\n",
       "        9, 10, 10,  8,  8, 10,  9, 10, 10,  9,  8,  9,  9,  9, 10, 10,  9,\n",
       "        9,  8, 10,  9, 10, 10, 10,  8, 10,  9,  9,  9, 10, 10, 10, 10, 10,\n",
       "       10,  8, 10,  9,  8, 10,  8,  9, 10, 10,  9, 10,  9,  9,  8,  9, 10,\n",
       "        9,  8, 10, 10, 10,  9, 10, 10,  9,  9,  9,  8,  8,  9, 10,  9, 10,\n",
       "        9,  8, 10, 10, 10,  9, 10, 10,  9,  8,  9, 10,  8,  9,  8, 10, 10,\n",
       "       10,  9, 10,  9, 10,  7,  9,  9, 10, 10,  8, 10,  9,  8, 10,  9,  5,\n",
       "       10,  9,  9,  9,  9, 10,  8, 10,  8,  9, 10, 10,  9, 10,  9,  4,  8,\n",
       "        9,  8,  9,  8, 10, 10,  7, 10,  9, 10,  9, 10,  8,  9,  8, 10,  9,\n",
       "        8,  8, 10,  9,  9,  9, 10, 10,  5, 10,  9, 10, 10,  9,  9,  9,  9,\n",
       "       10, 10,  8, 10, 10, 10, 10, 10, 10, 10,  8,  9, 10,  9, 10, 10,  9,\n",
       "        9,  8,  9, 10,  8,  8, 10,  9,  9,  9,  9, 10, 10, 10, 10,  9, 10,\n",
       "        9, 10,  9,  9, 10, 10,  8,  8, 10,  9, 10,  8,  5, 10,  8, 10, 10,\n",
       "        8, 10,  9, 10, 10,  9, 10, 10, 10,  9,  8, 10, 10,  8, 10, 10, 10,\n",
       "        9, 10, 10,  9,  9,  9, 10, 10, 10,  8, 10, 10, 10, 10, 10, 10,  9,\n",
       "       10, 10,  9,  9,  9,  8,  9,  8, 10, 10,  8,  8, 10,  9,  9, 10,  9,\n",
       "       10,  9, 10, 10,  8,  9,  8, 10,  7,  5, 10,  9, 10, 10,  9, 10, 10,\n",
       "       10,  9, 10, 10, 10, 10,  9, 10,  9,  9, 10,  8,  8, 10,  8,  9,  9,\n",
       "        9,  9,  8,  9,  1, 10, 10, 10,  8, 10, 10,  9, 10,  8,  9, 10, 10,\n",
       "        9,  9, 10, 10,  9,  5,  9, 10,  9, 10,  9, 10, 10,  9, 10,  8,  9,\n",
       "       10,  9,  8, 10, 10, 10,  9,  9,  9, 10,  9,  9, 10, 10, 10, 10, 10,\n",
       "        8,  9, 10, 10,  9, 10,  9,  5,  8,  9,  9,  9,  9,  9,  9, 10,  8,\n",
       "       10,  8,  9,  8,  9,  9, 10,  9,  9, 10,  8,  8,  9, 10,  8,  8, 10,\n",
       "       10,  9,  9,  9, 10,  8, 10, 10,  9, 10,  9, 10,  9, 10, 10, 10, 10,\n",
       "        8, 10, 10, 10, 10, 10,  5,  8, 10,  9,  8, 10, 10, 10,  8, 10, 10,\n",
       "       10, 10, 10,  9, 10, 10,  9, 10,  8, 10,  9,  9,  8,  9,  9,  9, 10,\n",
       "        8,  8,  8, 10, 10, 10, 10, 10,  9,  9,  9,  5,  8, 10, 10, 10, 10,\n",
       "       10, 10, 10,  9, 10, 10,  9,  9,  9, 10,  8,  8,  9,  9, 10, 10, 10,\n",
       "       10, 10,  8,  9,  8, 10, 10, 10, 10,  8,  9,  9,  9, 10, 10,  8,  9,\n",
       "       10, 10,  9,  8, 10, 10, 10,  9, 10,  9,  9,  8,  9, 10,  8,  8, 10,\n",
       "       10,  5, 10, 10, 10, 10,  9,  9, 10,  9,  9,  8,  9, 10,  8,  9,  9,\n",
       "       10,  8, 10, 10,  8,  9,  9, 10,  8, 10,  8,  9, 10, 10, 10, 10,  8,\n",
       "        9, 10, 10,  9,  9,  9, 10, 10,  9,  8,  8, 10,  8, 10,  8,  9,  8,\n",
       "        9, 10, 10,  9, 10, 10,  9,  9,  9,  9,  9, 10,  9,  9, 10, 10, 10,\n",
       "        9,  9,  9, 10,  7,  9,  8,  7,  8, 10, 10,  9,  9,  8, 10,  9, 10,\n",
       "        9, 10,  9, 10,  9, 10, 10,  9,  9,  8, 10, 10, 10, 10,  9, 10,  9,\n",
       "        9, 10,  9, 10,  8, 10, 10,  8, 10,  8,  9,  8,  9, 10, 10,  9,  8,\n",
       "        9,  9, 10, 10,  9,  9, 10, 10,  9,  8,  9, 10,  9,  9,  8,  9,  9,\n",
       "        9,  8,  9, 10, 10, 10,  9, 10, 10,  9, 10, 10,  8,  8, 10, 10, 10,\n",
       "       10,  9,  8,  9,  9, 10,  9, 10, 10, 10,  8, 10, 10,  9,  9, 10,  9,\n",
       "        9,  9, 10, 10, 10,  9,  8, 10, 10,  9,  8,  9, 10,  9,  8,  8,  9,\n",
       "       10,  9,  9, 10, 10,  9, 10, 10,  9,  8,  9,  8, 10,  9,  9, 10, 10,\n",
       "        9,  8, 10,  9, 10,  9, 10, 10, 10,  8,  8,  9,  9,  9, 10, 10, 10,\n",
       "       10, 10,  8,  9, 10, 10,  8, 10,  9,  9, 10, 10,  9,  9,  8,  8,  8,\n",
       "        8,  8, 10, 10, 10, 10,  9,  9, 10, 10,  8,  8,  8, 10, 10,  8,  8,\n",
       "        8,  9,  8,  8,  9,  8, 10, 10,  9,  9, 10, 10,  9,  9,  9,  9, 10,\n",
       "        9, 10,  9,  8,  8,  5,  9, 10,  9,  8,  9, 10,  8,  9, 10, 10,  9,\n",
       "        9,  9,  9,  9, 10, 10,  8, 10,  9,  9,  9, 10,  9,  9,  9, 10,  5,\n",
       "       10, 10,  9, 10, 10,  9, 10, 10,  9,  8, 10,  9, 10, 10,  9,  9, 10,\n",
       "        5,  8, 10,  8, 10,  9,  9, 10,  9, 10,  8,  9,  5, 10, 10,  8, 10,\n",
       "        8, 10,  9,  9,  9, 10, 10,  9, 10,  8,  9,  9,  8,  8,  9, 10, 10,\n",
       "       10,  9,  9, 10,  8, 10,  9,  9, 10, 10,  8,  9, 10, 10,  8, 10, 10,\n",
       "       10, 10,  8,  9, 10,  8,  9, 10,  8, 10,  9,  8, 10,  9, 10, 10,  8,\n",
       "       10, 10,  8,  9, 10,  8,  8,  9,  9,  8,  9,  9, 10,  9,  9,  9, 10,\n",
       "        8,  8, 10,  7,  9, 10,  9, 10, 10,  8,  9,  8,  8, 10, 10,  9,  8,\n",
       "       10, 10,  9, 10, 10, 10,  9,  8,  8, 10,  8,  9,  9, 10],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём объект, который будет токенизировать данные\n",
    "analyzer = CountVectorizer().build_analyzer() \n",
    "\n",
    "# Токенизируем набор данных\n",
    "docs = [] \n",
    "for document in X: \n",
    "    docs.append(analyzer(document.replace('_', ''))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_analyzer = pd.Series([' '.join(doc) for doc in docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer(use_idf=False)), ('clf', SVC())])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_analyzer_svm = Pipeline([('vector', CountVectorizer(ngram_range=(1, 2))), \n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)), \n",
    "                         ('clf', svm.SVC())]) \n",
    "text_analyzer_svm.fit(X_analyzer, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь предскажем оценки на входных данных c analyzer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой гад сказал мне, что \"Центурион\" - кино и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да что делать с этими англичосами? Снять фильм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>И снова нас ждет пересказ событий MS Зетa Ганд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Даже странно, что Князь Серебряный не входит в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вообще-то книгу я уже давно читал, но, кажется...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Какой гад сказал мне, что \"Центурион\" - кино и...\n",
       "1  Да что делать с этими англичосами? Снять фильм...\n",
       "2  И снова нас ждет пересказ событий MS Зетa Ганд...\n",
       "3  Даже странно, что Князь Серебряный не входит в...\n",
       "4  Вообще-то книгу я уже давно читал, но, кажется..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные из файла `dataset_40757_2.txt`, посмотрим на них\n",
    "\n",
    "dataset2 = pd.read_csv(\n",
    "    'C:/Users/Григорий/Notebooks (Pyton)/Обработка_языка/Практическое_задание_3/dataset_40757_2.txt', \n",
    "    sep='\\n', header=None, encoding='utf-8', error_bad_lines=False, quoting=csv.QUOTE_NONE) \n",
    "'''Так как поля содержат кавычки, чтобы не возникало ошибок, \n",
    "                   не будем обрабатывать: quoting=csv.QUOTE_NONE'''\n",
    "dataset2.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём объект, который будет токенизировать данные\n",
    "analyzer = CountVectorizer().build_analyzer() \n",
    "\n",
    "# Токенизируем набор данных\n",
    "docs2 = [] \n",
    "for document in dataset2[0]: \n",
    "    docs2.append(analyzer(document.replace('_', ''))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним токенизированный текст в переменную: \n",
    "\n",
    "X_analyzer2 = pd.Series([' '.join(doc) for doc in docs2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предскажем значения \n",
    "\n",
    "y_pred2 = text_analyzer_svm.predict(X_analyzer2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним файл `predictions2.txt` \n",
    "\n",
    "pd.DataFrame(y_pred2).to_csv('predictions2.txt', sep='\\n', header=None, index=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простая модель без Наташи показала лучший результат 65.42 балла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
